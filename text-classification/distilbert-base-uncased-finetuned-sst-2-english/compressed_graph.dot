strict digraph  {
"0 /nncf_model_input_0";
"1 /nncf_model_input_1";
"2 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFEmbedding[word_embeddings]/embedding_0";
"3 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFEmbedding[position_embeddings]/embedding_0";
"4 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/__add___0";
"5 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"6 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0";
"7 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"8 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"9 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"10 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_0";
"11 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_0";
"12 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"13 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"14 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"15 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"16 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_1";
"17 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_1";
"18 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"19 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"20 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"21 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_2";
"22 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_2";
"23 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__truediv___0";
"24 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"25 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_3";
"26 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_0";
"27 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__eq___0";
"28 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_3";
"29 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/expand_as_0";
"30 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/masked_fill_0";
"31 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/softmax_0";
"32 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"33 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_1";
"34 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"35 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_4";
"36 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/contiguous_0";
"37 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_4";
"38 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"39 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"40 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___0";
"41 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"42 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"43 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"44 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"45 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"46 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"47 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"48 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"49 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/Dropout[dropout]/dropout_0";
"50 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___1";
"51 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"52 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"53 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"54 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"55 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_0";
"56 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_0";
"57 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"58 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"59 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"60 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"61 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_1";
"62 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_1";
"63 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"64 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"65 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"66 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_2";
"67 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_2";
"68 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__truediv___0";
"69 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"70 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_3";
"71 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_0";
"72 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__eq___0";
"73 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_3";
"74 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/expand_as_0";
"75 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/masked_fill_0";
"76 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/softmax_0";
"77 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"78 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_1";
"79 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"80 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_4";
"81 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/contiguous_0";
"82 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_4";
"83 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"84 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"85 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___0";
"86 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"87 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"88 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"89 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"90 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"91 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"92 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"93 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"94 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/Dropout[dropout]/dropout_0";
"95 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___1";
"96 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"97 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"98 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"99 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"100 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_0";
"101 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_0";
"102 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"103 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"104 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"105 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"106 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_1";
"107 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_1";
"108 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"109 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"110 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"111 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_2";
"112 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_2";
"113 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__truediv___0";
"114 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"115 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_3";
"116 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_0";
"117 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__eq___0";
"118 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_3";
"119 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/expand_as_0";
"120 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/masked_fill_0";
"121 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/softmax_0";
"122 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"123 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_1";
"124 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"125 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_4";
"126 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/contiguous_0";
"127 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_4";
"128 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"129 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"130 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___0";
"131 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"132 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"133 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"134 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"135 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"136 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"137 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"138 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"139 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/Dropout[dropout]/dropout_0";
"140 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___1";
"141 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"142 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"143 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"144 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"145 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_0";
"146 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_0";
"147 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"148 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"149 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"150 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"151 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_1";
"152 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_1";
"153 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"154 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"155 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"156 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_2";
"157 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_2";
"158 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__truediv___0";
"159 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"160 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_3";
"161 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_0";
"162 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__eq___0";
"163 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_3";
"164 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/expand_as_0";
"165 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/masked_fill_0";
"166 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/softmax_0";
"167 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"168 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_1";
"169 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"170 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_4";
"171 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/contiguous_0";
"172 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_4";
"173 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"174 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"175 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___0";
"176 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"177 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"178 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"179 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"180 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"181 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"182 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"183 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"184 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/Dropout[dropout]/dropout_0";
"185 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___1";
"186 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"187 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"188 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"189 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"190 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_0";
"191 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_0";
"192 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"193 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"194 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"195 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"196 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_1";
"197 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_1";
"198 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"199 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"200 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"201 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_2";
"202 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_2";
"203 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__truediv___0";
"204 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"205 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_3";
"206 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_0";
"207 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__eq___0";
"208 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_3";
"209 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/expand_as_0";
"210 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/masked_fill_0";
"211 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/softmax_0";
"212 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"213 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_1";
"214 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"215 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_4";
"216 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/contiguous_0";
"217 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_4";
"218 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"219 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"220 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___0";
"221 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"222 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"223 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"224 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"225 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"226 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"227 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"228 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"229 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/Dropout[dropout]/dropout_0";
"230 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___1";
"231 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"232 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"233 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"234 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"235 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_0";
"236 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_0";
"237 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"238 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"239 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"240 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"241 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_1";
"242 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_1";
"243 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"244 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"245 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"246 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_2";
"247 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_2";
"248 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__truediv___0";
"249 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"250 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_3";
"251 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_0";
"252 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__eq___0";
"253 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_3";
"254 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/expand_as_0";
"255 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/masked_fill_0";
"256 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/softmax_0";
"257 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"258 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_1";
"259 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"260 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_4";
"261 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/contiguous_0";
"262 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_4";
"263 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"264 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"265 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___0";
"266 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"267 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"268 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"269 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"270 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"271 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"272 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"273 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"274 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/Dropout[dropout]/dropout_0";
"275 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___1";
"276 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"277 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/AsymmetricQuantizer/asymmetric_quantize_0";
"278 DistilBertForSequenceClassification/__getitem___0";
"279 DistilBertForSequenceClassification/NNCFLinear[pre_classifier]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"280 DistilBertForSequenceClassification/NNCFLinear[pre_classifier]/linear_0";
"281 DistilBertForSequenceClassification/ReLU/relu_0";
"282 DistilBertForSequenceClassification/ReLU/AsymmetricQuantizer/asymmetric_quantize_0";
"283 DistilBertForSequenceClassification/Dropout[dropout]/dropout_0";
"284 DistilBertForSequenceClassification/NNCFLinear[classifier]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"285 DistilBertForSequenceClassification/NNCFLinear[classifier]/linear_0";
"286 /nncf_model_output_0";
"0 /nncf_model_input_0" -> "27 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(1, 52) \n0 -> 0", style=dashed];
"0 /nncf_model_input_0" -> "72 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(1, 52) \n0 -> 0", style=dashed];
"0 /nncf_model_input_0" -> "117 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(1, 52) \n0 -> 0", style=dashed];
"0 /nncf_model_input_0" -> "162 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(1, 52) \n0 -> 0", style=dashed];
"0 /nncf_model_input_0" -> "207 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(1, 52) \n0 -> 0", style=dashed];
"0 /nncf_model_input_0" -> "252 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(1, 52) \n0 -> 0", style=dashed];
"1 /nncf_model_input_1" -> "2 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFEmbedding[word_embeddings]/embedding_0"  [label="(1, 52) \n0 -> 0", style=dashed];
"2 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFEmbedding[word_embeddings]/embedding_0" -> "4 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/__add___0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"3 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFEmbedding[position_embeddings]/embedding_0" -> "4 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/__add___0"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"4 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/__add___0" -> "5 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"5 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "6 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"6 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0" -> "8 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"6 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0" -> "13 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"6 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0" -> "19 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"6 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0" -> "40 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___0"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"7 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "9 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"8 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "9 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"9 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "10 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"10 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_0" -> "11 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"11 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_0" -> "23 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"12 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "14 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"13 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "14 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"14 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "15 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"15 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "16 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"16 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_1" -> "17 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"17 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_1" -> "25 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"18 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "20 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"19 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "20 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"20 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "21 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_2"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"21 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_2" -> "22 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"22 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_2" -> "33 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 64) \n0 -> 1", style=solid];
"23 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__truediv___0" -> "24 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"24 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "26 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"25 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_3" -> "26 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 64, 52) \n0 -> 1", style=solid];
"26 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_0" -> "29 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=solid];
"26 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_0" -> "30 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"27 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__eq___0" -> "28 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_3"  [label="(1, 52) \n0 -> 0", style=dashed];
"28 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_3" -> "29 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 1, 1, 52) \n0 -> 0", style=dashed];
"29 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/expand_as_0" -> "30 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=dashed];
"30 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "31 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"31 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/softmax_0" -> "32 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"32 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "33 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"33 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_1" -> "34 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"34 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "35 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"35 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_4" -> "36 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"36 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/contiguous_0" -> "37 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_4"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"37 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_4" -> "39 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"38 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "39 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"39 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "40 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"40 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___0" -> "41 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"41 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "43 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"41 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "50 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___1"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"42 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "44 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"43 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "44 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"44 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "45 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"45 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "46 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"46 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "48 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"47 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "48 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"48 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "49 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"49 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "50 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"50 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___1" -> "51 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"51 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "53 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"51 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "58 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"51 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "64 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"51 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "85 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___0"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"52 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "54 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"53 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "54 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"54 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "55 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"55 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_0" -> "56 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"56 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_0" -> "68 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"57 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "59 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"58 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "59 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"59 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "60 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"60 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "61 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"61 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_1" -> "62 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"62 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_1" -> "70 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"63 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "65 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"64 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "65 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"65 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "66 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_2"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"66 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_2" -> "67 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"67 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_2" -> "78 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 64) \n0 -> 1", style=solid];
"68 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__truediv___0" -> "69 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"69 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "71 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"70 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_3" -> "71 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 64, 52) \n0 -> 1", style=solid];
"71 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_0" -> "74 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=solid];
"71 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_0" -> "75 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"72 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__eq___0" -> "73 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_3"  [label="(1, 52) \n0 -> 0", style=dashed];
"73 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_3" -> "74 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 1, 1, 52) \n0 -> 0", style=dashed];
"74 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/expand_as_0" -> "75 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=dashed];
"75 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "76 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"76 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/softmax_0" -> "77 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"77 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "78 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"78 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_1" -> "79 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"79 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "80 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"80 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_4" -> "81 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"81 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/contiguous_0" -> "82 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_4"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"82 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_4" -> "84 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"83 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "84 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"84 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "85 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"85 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___0" -> "86 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"86 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "88 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"86 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "95 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___1"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"87 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "89 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"88 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "89 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"89 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "90 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"90 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "91 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"91 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "93 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"92 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "93 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"93 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "94 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"94 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "95 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"95 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___1" -> "96 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"96 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "98 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"96 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "103 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"96 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "109 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"96 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "130 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___0"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"97 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "99 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"98 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "99 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"99 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "100 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"100 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_0" -> "101 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"101 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_0" -> "113 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"102 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "104 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"103 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "104 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"104 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "105 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"105 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "106 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"106 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_1" -> "107 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"107 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_1" -> "115 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"108 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "110 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"109 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "110 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"110 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "111 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_2"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"111 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_2" -> "112 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"112 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_2" -> "123 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 64) \n0 -> 1", style=solid];
"113 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__truediv___0" -> "114 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"114 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "116 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"115 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_3" -> "116 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 64, 52) \n0 -> 1", style=solid];
"116 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_0" -> "119 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=solid];
"116 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_0" -> "120 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"117 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__eq___0" -> "118 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_3"  [label="(1, 52) \n0 -> 0", style=dashed];
"118 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_3" -> "119 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 1, 1, 52) \n0 -> 0", style=dashed];
"119 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/expand_as_0" -> "120 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=dashed];
"120 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "121 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"121 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/softmax_0" -> "122 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"122 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "123 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"123 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_1" -> "124 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"124 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "125 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"125 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_4" -> "126 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"126 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/contiguous_0" -> "127 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_4"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"127 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_4" -> "129 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"128 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "129 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"129 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "130 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"130 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___0" -> "131 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"131 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "133 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"131 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "140 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___1"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"132 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "134 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"133 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "134 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"134 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "135 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"135 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "136 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"136 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "138 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"137 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "138 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"138 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "139 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"139 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "140 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"140 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___1" -> "141 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"141 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "143 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"141 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "148 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"141 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "154 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"141 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "175 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___0"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"142 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "144 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"143 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "144 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"144 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "145 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"145 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_0" -> "146 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"146 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_0" -> "158 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"147 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "149 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"148 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "149 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"149 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "150 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"150 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "151 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"151 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_1" -> "152 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"152 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_1" -> "160 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"153 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "155 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"154 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "155 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"155 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "156 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_2"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"156 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_2" -> "157 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"157 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_2" -> "168 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 64) \n0 -> 1", style=solid];
"158 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__truediv___0" -> "159 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"159 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "161 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"160 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_3" -> "161 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 64, 52) \n0 -> 1", style=solid];
"161 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_0" -> "164 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=solid];
"161 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_0" -> "165 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"162 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__eq___0" -> "163 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_3"  [label="(1, 52) \n0 -> 0", style=dashed];
"163 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_3" -> "164 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 1, 1, 52) \n0 -> 0", style=dashed];
"164 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/expand_as_0" -> "165 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=dashed];
"165 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "166 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"166 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/softmax_0" -> "167 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"167 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "168 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"168 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_1" -> "169 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"169 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "170 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"170 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_4" -> "171 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"171 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/contiguous_0" -> "172 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_4"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"172 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_4" -> "174 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"173 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "174 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"174 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "175 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"175 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___0" -> "176 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"176 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "178 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"176 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "185 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___1"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"177 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "179 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"178 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "179 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"179 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "180 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"180 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "181 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"181 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "183 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"182 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "183 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"183 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "184 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"184 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "185 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"185 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___1" -> "186 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"186 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "188 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"186 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "193 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"186 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "199 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"186 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "220 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___0"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"187 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "189 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"188 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "189 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"189 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "190 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"190 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_0" -> "191 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"191 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_0" -> "203 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"192 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "194 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"193 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "194 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"194 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "195 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"195 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "196 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"196 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_1" -> "197 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"197 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_1" -> "205 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"198 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "200 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"199 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "200 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"200 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "201 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_2"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"201 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_2" -> "202 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"202 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_2" -> "213 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 64) \n0 -> 1", style=solid];
"203 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__truediv___0" -> "204 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"204 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "206 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"205 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_3" -> "206 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 64, 52) \n0 -> 1", style=solid];
"206 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_0" -> "209 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=solid];
"206 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_0" -> "210 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"207 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__eq___0" -> "208 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_3"  [label="(1, 52) \n0 -> 0", style=dashed];
"208 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_3" -> "209 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 1, 1, 52) \n0 -> 0", style=dashed];
"209 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/expand_as_0" -> "210 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=dashed];
"210 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "211 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"211 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/softmax_0" -> "212 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"212 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "213 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"213 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_1" -> "214 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"214 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "215 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"215 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_4" -> "216 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"216 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/contiguous_0" -> "217 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_4"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"217 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_4" -> "219 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"218 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "219 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"219 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "220 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"220 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___0" -> "221 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"221 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "223 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"221 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "230 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___1"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"222 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "224 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"223 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "224 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"224 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "225 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"225 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "226 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"226 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "228 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"227 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "228 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"228 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "229 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"229 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "230 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"230 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___1" -> "231 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"231 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "233 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"231 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "238 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"231 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "244 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"231 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "265 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___0"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"232 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "234 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"233 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "234 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"234 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "235 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"235 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_0" -> "236 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"236 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_0" -> "248 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"237 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "239 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"238 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "239 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"239 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "240 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"240 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "241 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"241 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_1" -> "242 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"242 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_1" -> "250 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"243 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "245 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"244 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "245 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"245 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "246 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_2"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"246 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_2" -> "247 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"247 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_2" -> "258 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 64) \n0 -> 1", style=solid];
"248 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__truediv___0" -> "249 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"249 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "251 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"250 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_3" -> "251 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(1, 12, 64, 52) \n0 -> 1", style=solid];
"251 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_0" -> "254 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=solid];
"251 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_0" -> "255 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"252 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__eq___0" -> "253 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_3"  [label="(1, 52) \n0 -> 0", style=dashed];
"253 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_3" -> "254 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(1, 1, 1, 52) \n0 -> 0", style=dashed];
"254 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/expand_as_0" -> "255 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(1, 12, 52, 52) \n0 -> 1", style=dashed];
"255 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "256 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"256 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/softmax_0" -> "257 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"257 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "258 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(1, 12, 52, 52) \n0 -> 0", style=solid];
"258 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_1" -> "259 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"259 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "260 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(1, 12, 52, 64) \n0 -> 0", style=solid];
"260 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_4" -> "261 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"261 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/contiguous_0" -> "262 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_4"  [label="(1, 52, 12, 64) \n0 -> 0", style=solid];
"262 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_4" -> "264 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"263 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "264 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"264 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "265 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"265 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___0" -> "266 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"266 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "268 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"266 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "275 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___1"  [label="(1, 52, 768) \n0 -> 1", style=solid];
"267 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "269 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"268 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "269 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"269 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "270 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"270 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "271 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"271 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "273 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(1, 52, 3072) \n0 -> 0", style=solid];
"272 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "273 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"273 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "274 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"274 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "275 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___1"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"275 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___1" -> "276 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"276 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "277 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"277 DistilBertForSequenceClassification/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/AsymmetricQuantizer/asymmetric_quantize_0" -> "278 DistilBertForSequenceClassification/__getitem___0"  [label="(1, 52, 768) \n0 -> 0", style=solid];
"278 DistilBertForSequenceClassification/__getitem___0" -> "280 DistilBertForSequenceClassification/NNCFLinear[pre_classifier]/linear_0"  [label="(1, 768) \n0 -> 0", style=solid];
"279 DistilBertForSequenceClassification/NNCFLinear[pre_classifier]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "280 DistilBertForSequenceClassification/NNCFLinear[pre_classifier]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"280 DistilBertForSequenceClassification/NNCFLinear[pre_classifier]/linear_0" -> "281 DistilBertForSequenceClassification/ReLU/relu_0"  [label="(1, 768) \n0 -> 0", style=solid];
"281 DistilBertForSequenceClassification/ReLU/relu_0" -> "282 DistilBertForSequenceClassification/ReLU/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 768) \n0 -> 0", style=solid];
"282 DistilBertForSequenceClassification/ReLU/AsymmetricQuantizer/asymmetric_quantize_0" -> "283 DistilBertForSequenceClassification/Dropout[dropout]/dropout_0"  [label="(1, 768) \n0 -> 0", style=solid];
"283 DistilBertForSequenceClassification/Dropout[dropout]/dropout_0" -> "285 DistilBertForSequenceClassification/NNCFLinear[classifier]/linear_0"  [label="(1, 768) \n0 -> 0", style=solid];
"284 DistilBertForSequenceClassification/NNCFLinear[classifier]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "285 DistilBertForSequenceClassification/NNCFLinear[classifier]/linear_0"  [label="(2, 768) \n0 -> 1", style=solid];
"285 DistilBertForSequenceClassification/NNCFLinear[classifier]/linear_0" -> "286 /nncf_model_output_0"  [label="(1, 2) \n0 -> 0", style=solid];
}
